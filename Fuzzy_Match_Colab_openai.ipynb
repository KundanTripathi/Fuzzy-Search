{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfz5Gi3XkF8y"
      },
      "outputs": [],
      "source": [
        "!pip install gradio pandas langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IVoNoRHCTun",
        "outputId": "338d0b5b-d550-414f-817a-efe34bb17db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "wxm2gap1nsAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "2BmEjxoVoMeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "YNkVn-NBpRsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyxPKUo0pf1w",
        "outputId": "7246e274-3713-47fc-92f2-eb90f7187ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "#docvecs = FAISS.from_texts(comp['NAME'], embeddings)"
      ],
      "metadata": {
        "id": "tYpL_-6TptyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "xZ27u1n8FHF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paGO1Ex5FP3I",
        "outputId": "d276d857-668d-4cf4-ac0e-0f591bf1052d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_excel(r'/content/gdrive/My Drive/Colab Notebooks/files_1.xlsx')\n",
        "df2 = pd.read_excel(r'/content/gdrive/My Drive/Colab Notebooks/files_2.xlsx')"
      ],
      "metadata": {
        "id": "TcWCwuUkGPCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gspread==3.6"
      ],
      "metadata": {
        "id": "AUh8E5u3O9XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "l4FVy_uVUkAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "def transform_dataframes(file1, file2):\n",
        "    df1 = pd.read_excel(file1)\n",
        "    df2 = pd.read_excel(file2)\n",
        "\n",
        "    dataframes_1 = df1\n",
        "    dataframes_2 = df2\n",
        "    docvecs = FAISS.from_texts(dataframes_1['NAME'], embeddings)\n",
        "    match = {}\n",
        "    for i in dataframes_2['LIST']:\n",
        "        match[i]=[docvecs.similarity_search_with_score(i)]\n",
        "\n",
        "    lst = []\n",
        "    matching_comp = [\"matching_comp_01\",\"matching_comp_02\",\"matching_comp_03\",\"matching_comp_04\"]\n",
        "    matching_dist = [\"matching_distance_01\",\"matching_distance_02\",\"matching_distance_03\",\"matching_distance_04\"]\n",
        "    for i in match.keys():\n",
        "        final_dict= {}\n",
        "        final_dict[\"company\"] = [i.strip()]\n",
        "        for j in range(4):\n",
        "            final_dict[matching_comp[j]] = [match[i][0][j][0].page_content]\n",
        "            final_dict[matching_dist[j]] = [match[i][0][j][1]]\n",
        "        lst.append(final_dict)\n",
        "    out = pd.DataFrame(columns = lst[0].keys())\n",
        "    for i in range(len(lst)):\n",
        "        out = pd.concat([out,pd.DataFrame(lst[i])],axis=0)\n",
        "    out = out.reset_index(drop=True)\n",
        "\n",
        "    return out\n",
        "\n",
        "st.title(\"Excel Files Transformation and Display\")\n",
        "\n",
        "# Upload Excel files\n",
        "uploaded_file1 = st.file_uploader(\"Upload Excel File 1\", type=[\"xlsx\"])\n",
        "uploaded_file2 = st.file_uploader(\"Upload Excel File 2\", type=[\"xlsx\"])\n",
        "\n",
        "# Perform transformation on button click\n",
        "if st.button(\"Transform Dataframes\"):\n",
        "    if uploaded_file1 is not None and uploaded_file2 is not None:\n",
        "        transformed_df = transform_dataframes(uploaded_file1, uploaded_file2)\n",
        "        st.write(\"Transformed DataFrame:\")\n",
        "        st.write(transformed_df)\n",
        "    else:\n",
        "        st.warning(\"Please upload both Excel files.\")\n",
        "\n",
        "st.text(\"Note: After uploading the files, click the 'Transform Dataframes' button to see the transformed result.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXGJWjgxUkUX",
        "outputId": "011ff4a4-bea4-4987-ebbe-cfbe166acc15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-08-15 17:54:50.565 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py [ARGUMENTS]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}